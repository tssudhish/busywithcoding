{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### $Q$-learning as a Regression Problem\n",
    "\n",
    "When we first learned about $Q$-learning, we used the Bellman equation to learn the $Q$ function:\n",
    "$$\n",
    "Q(s_t, a_t) \\gets Q(s_t, a_t) + \\alpha \\left( r_t + (1-d_t)\\gamma \\max_{a_{t+1}} \\left( Q(s_{t+1}, a_{t+1}) \\right) - Q(s_t, a_t) \\right)\n",
    "$$\n",
    "\n",
    "Compare this to gradient descent for a regression problem:\n",
    "$$\n",
    "\\theta \\gets \\theta - \\alpha 2 \\left( \\hat{y} - y \\right) \\nabla_\\theta \\hat{y}\n",
    "$$\n",
    "\n",
    "These methods are essentially analogous: we update parameters about our function in a manner proportional to the difference between our prediction and the 'true' value. The difference for tabular $Q$-learning is that we essentially have a different parameter for each state-action pair. \n",
    "\n",
    "If we define the following loss function:\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{2} \\left( r_t + (1-d_t)\\gamma \\max_{a_{t+1}} \\left( Q(s_{t+1}, a_{t+1}) \\right) - Q(s_t, a_t) \\right)^2\n",
    "$$\n",
    "\n",
    "Then the gradient descent update rule is exactly the same as our q-learning update rule!\n",
    "\n",
    "### FrozenLake with Tensorflow\n",
    "\n",
    "Before diving deep into using techniques like deep neural networks, I want to show you how we might do $Q$-learning in tensorflow using the same `FrozenLake-v0` environment from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions, \n",
    "                 epsilon_i=1.0, \n",
    "                 epsilon_f=0.0, \n",
    "                 n_epsilon=0.1, \n",
    "                 alpha=0.5, \n",
    "                 gamma = 0.95,\n",
    "                 hidden_layers = []\n",
    "                ):\n",
    "        \n",
    "        self.epsilon_i = epsilon_i\n",
    "        self.epsilon_f = epsilon_f\n",
    "        self.epsilon = epsilon_i\n",
    "        self.n_epsilon = n_epsilon\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.Q = tf.Variable(tf.zeros((num_states, num_actions)), name=\"Q\")\n",
    "        self.optimizer = tf.keras.optimizers.SGD(alpha)\n",
    "\n",
    "    def decay_epsilon(self, n):\n",
    "        self.epsilon = max(\n",
    "            self.epsilon_f, \n",
    "            self.epsilon_i - (n/self.n_epsilon)*(self.epsilon_i - self.epsilon_f))\n",
    "    \n",
    "    def act(self, s_t):\n",
    "#         print(\"np.random.rand(): {} < self.epsilon: {}\".format(np.random.rand(),self.epsilon))\n",
    "        action=-1\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action= np.random.randint(self.num_actions)\n",
    "            print(\"Random Action selected : {}\".format(action))\n",
    "        else:\n",
    "#             max_v_current=[i for i,val in enumerate(s_t) if val == s_t.max()][0]\n",
    "            print(self.Q)\n",
    "#             print(\"np.argmax(self.Q[max_v_current]) = {}\".format(np.argmax(self.Q[max_v_current])))\n",
    "#             print(np.argmax(self.Q.numpy(), axis=0))\n",
    "            action= np.argmax(np.argmax(self.Q.numpy(), axis=0))\n",
    "            \n",
    "            #np.argmax(self.Q[max_v_current])\n",
    "            print(\"Predicted Action selected : {}\".format(action))\n",
    "#         print(\"Action = {}\".format(action))\n",
    "#         print(self.Q)\n",
    "        return action\n",
    "    \n",
    "    def update(self, s_t, a_t, r_t, s_t_next, d_t):\n",
    "#         print(\"------------- update -------------\")\n",
    "#         print(\"*\"*50)\n",
    "#         print(s_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(a_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(r_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(\"-------------s_t_next-------------\")\n",
    "#         print(s_t_next.transpose())\n",
    "#         print(\"*\"*50)\n",
    "#         print(\"-------------d_t     -------------\")\n",
    "#         print(d_t)\n",
    "        \n",
    "#         print(\"*\"*50)\n",
    "#         print(self.Q[[i for i,val in enumerate(s_t_next) if val == s_t_next.max()][0]])\n",
    "        max_v_next=[i for i,val in enumerate(s_t_next) if val == s_t_next.max()][0]\n",
    "        max_v_current=[i for i,val in enumerate(s_t) if val == s_t.max()][0]\n",
    "#         print(\"*\"*50)\n",
    "#         print(np.max(self.Q[max_v_next]))\n",
    "        Q_next = tf.stop_gradient(np.max(self.Q[max_v_next]))\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = 0.5*tf.reduce_mean(r_t + (1-d_t)*self.gamma*Q_next -  self.Q[max_v_current, a_t])**2\n",
    "        grads = tape.gradient(loss, [self.Q])\n",
    "        self.optimizer.apply_gradients(zip(grads, [self.Q]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, window=100):\n",
    "    sns.lineplot(\n",
    "        data=data.rolling(window=window).mean()[window-1::window]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env,\n",
    "         T=100000, alpha=0.8, gamma=0.95, epsilon_i = 1.0, epsilon_f = 0.0, n_epsilon = 0.1):\n",
    "#    env = gym.make(env_name)\n",
    "#    num_states = env.observation_space.n\n",
    "#    num_actions = env.action_space.n\n",
    "    num_states=len(env.reset())\n",
    "    num_actions=4\n",
    "    agent = Agent(num_states, num_actions, alpha=alpha, gamma=gamma, epsilon_i=epsilon_i, epsilon_f=epsilon_f, n_epsilon = n_epsilon)\n",
    "    \n",
    "#     print(agent.Q)\n",
    "    rewards = []\n",
    "    episode_rewards = 0\n",
    "    \n",
    "    s_t_act = env.reset()\n",
    "    s_t=s_t_act/np.max(s_t_act)\n",
    "    \n",
    "#     print(s_t)\n",
    "    for t in range(T):\n",
    "        print(\"Iteration: {}\".format(t))\n",
    "#         print(agent.Q)\n",
    "        a_t = agent.act(s_t)\n",
    "#         print(\"Action: {}\".format(a_t))\n",
    "        s_t_next_act, r_t, d_t, info = env.step(a_t)\n",
    "        s_t_next=s_t_next_act/np.max(s_t_next_act)\n",
    "#         print(\"{}\\n{}\".format(\"-\"*50,s_t_next))\n",
    "#         print(\"{}\\n{}\".format(\"-\"*50,r_t))\n",
    "#         print(env.game_state)\n",
    "        agent.update(s_t, a_t, r_t, s_t_next, d_t)\n",
    "        agent.decay_epsilon(t/T)\n",
    "        s_t = s_t_next\n",
    "        episode_rewards += r_t\n",
    "#         print(\"Episode Reward: {}\".format(episode_rewards))\n",
    "#         print(\"Game is dead? {}\".format(d_t))\n",
    "        if d_t:\n",
    "            print(\"saving current episode rewards\")\n",
    "            rewards.append(episode_rewards)\n",
    "            episode_rewards = 0\n",
    "            s_t_act = env.reset()\n",
    "            s_t=s_t_act/np.max(s_t_act)\n",
    "            \n",
    "    plot(pd.DataFrame(rewards))\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Initialized Game_2048()\n",
      "GAME_MODE - training\n",
      "For function Game_2048.__init__, time taken 0.0009970664978027344\n",
      "Iteration: 0\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 2\n",
      "Iteration: 1\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 4\n",
      "Iteration: 2\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 4\n",
      "Iteration: 3\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 4\n",
      "Iteration: 4\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 8\n",
      "Iteration: 5\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 8\n",
      "Iteration: 6\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 7\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 8\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 9\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 10\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 8\n",
      "Iteration: 11\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 8\n",
      "Iteration: 12\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 13\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 8\n",
      "Iteration: 14\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 8\n",
      "Iteration: 15\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 16\n",
      "Iteration: 16\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 16\n",
      "Iteration: 17\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 18\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 19\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 20\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 16\n",
      "Iteration: 21\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 22\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 23\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 24\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 25\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 26\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 16\n",
      "Iteration: 27\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 28\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 16\n",
      "Iteration: 29\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 30\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 31\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 32\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 33\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 34\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 16\n",
      "Iteration: 35\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 16\n",
      "Iteration: 36\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 16\n",
      "Iteration: 37\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 16\n",
      "Iteration: 38\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 16\n",
      "Iteration: 39\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 16\n",
      "Iteration: 40\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 16\n",
      "Iteration: 41\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 42\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 43\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 44\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 32\n",
      "Iteration: 45\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 46\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 47\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 48\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 32\n",
      "Iteration: 49\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 50\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 51\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 52\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 53\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 32\n",
      "Iteration: 54\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 55\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 56\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 32\n",
      "Iteration: 57\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 58\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 32\n",
      "Iteration: 59\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 60\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 61\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 62\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 32\n",
      "Iteration: 63\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 64\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 65\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 32\n",
      "Iteration: 66\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 32\n",
      "Iteration: 67\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 68\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 69\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 70\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 71\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 72\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 73\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 74\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 75\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 76\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 77\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 78\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 79\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 80\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 81\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 82\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 83\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 84\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 85\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 86\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 87\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 88\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 89\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 90\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 91\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 92\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 93\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 94\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 95\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 96\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 97\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 98\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 99\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 100\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 101\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 102\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 103\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 104\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 105\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 106\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 107\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 108\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 109\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 110\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 64\n",
      "Iteration: 111\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 64\n",
      "Iteration: 112\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 113\n",
      "<tf.Variable 'Q:0' shape=(16, 4) dtype=float32, numpy=\n",
      "array([[1.4455035 , 1.408     , 0.        , 1.2401404 ],\n",
      "       [0.        , 0.        , 0.        , 2.2757888 ],\n",
      "       [0.        , 0.        , 2.73953   , 0.        ],\n",
      "       [0.15999997, 0.        , 0.        , 0.        ],\n",
      "       [0.608     , 2.73953   , 0.56033283, 0.73728   ],\n",
      "       [4.9701753 , 3.471912  , 4.055625  , 2.213069  ],\n",
      "       [2.5520132 , 1.07008   , 1.47926   , 3.1853654 ],\n",
      "       [0.        , 2.223184  , 1.994496  , 2.7712197 ],\n",
      "       [0.        , 0.        , 0.        , 0.5379195 ],\n",
      "       [4.121363  , 4.5445247 , 2.3266973 , 4.3385286 ],\n",
      "       [1.5136768 , 1.2551705 , 1.2551705 , 1.65154   ],\n",
      "       [0.        , 0.        , 0.        , 1.9916799 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [3.104422  , 2.3593607 , 3.5653768 , 2.6274712 ],\n",
      "       [1.4615681 , 0.        , 0.6794773 , 0.608     ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)>\n",
      "Predicted Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 114\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 115\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 64\n",
      "Iteration: 116\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 64\n",
      "Iteration: 117\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 118\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 119\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 120\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 121\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 122\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 123\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 124\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 125\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 126\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 127\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 128\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 129\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 130\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 131\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 132\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 133\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 134\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 135\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 136\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 137\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 138\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 139\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 140\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 141\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 142\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 143\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 144\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 145\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 146\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 147\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 148\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 149\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 150\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 151\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 152\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 153\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 154\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 155\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 156\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 157\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 158\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 159\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 160\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 161\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 162\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 163\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 164\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 165\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 166\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 167\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 168\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 169\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 170\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 171\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 172\n",
      "<tf.Variable 'Q:0' shape=(16, 4) dtype=float32, numpy=\n",
      "array([[1.4455035 , 1.408     , 0.        , 1.2401404 ],\n",
      "       [0.        , 0.        , 0.        , 2.2757888 ],\n",
      "       [0.        , 0.        , 2.73953   , 0.        ],\n",
      "       [0.15999997, 0.        , 0.        , 0.        ],\n",
      "       [0.608     , 5.760337  , 0.56033283, 3.029499  ],\n",
      "       [5.9413495 , 3.293207  , 6.1220284 , 5.0953555 ],\n",
      "       [6.1801543 , 6.8251295 , 6.5463896 , 6.918653  ],\n",
      "       [5.4527416 , 2.223184  , 3.1443315 , 2.4517977 ],\n",
      "       [0.4088188 , 2.7140555 , 0.        , 0.5379195 ],\n",
      "       [4.121363  , 4.5445247 , 2.3266973 , 4.3385286 ],\n",
      "       [3.3263307 , 6.5135274 , 6.878083  , 7.6976337 ],\n",
      "       [0.        , 0.        , 0.        , 1.9916799 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [3.104422  , 2.3593607 , 3.5653768 , 2.6274712 ],\n",
      "       [1.4615681 , 0.        , 0.6794773 , 0.608     ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)>\n",
      "Predicted Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 173\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 174\n",
      "<tf.Variable 'Q:0' shape=(16, 4) dtype=float32, numpy=\n",
      "array([[1.4455035 , 1.408     , 0.        , 1.2401404 ],\n",
      "       [0.        , 0.        , 0.        , 2.2757888 ],\n",
      "       [0.        , 0.        , 2.73953   , 0.        ],\n",
      "       [0.15999997, 0.        , 0.        , 0.        ],\n",
      "       [0.608     , 5.760337  , 0.56033283, 3.029499  ],\n",
      "       [6.5036955 , 3.293207  , 5.877147  , 5.0953555 ],\n",
      "       [6.1801543 , 6.8251295 , 6.5463896 , 6.918653  ],\n",
      "       [5.4527416 , 2.223184  , 3.1443315 , 2.4517977 ],\n",
      "       [0.4088188 , 2.7140555 , 0.        , 0.5379195 ],\n",
      "       [4.121363  , 4.5445247 , 2.3266973 , 4.3385286 ],\n",
      "       [3.3263307 , 6.5135274 , 6.878083  , 7.6976337 ],\n",
      "       [0.        , 0.        , 0.        , 1.9916799 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [3.104422  , 2.3593607 , 3.5653768 , 2.6274712 ],\n",
      "       [1.4615681 , 0.        , 0.6794773 , 0.608     ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)>\n",
      "Predicted Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 175\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 176\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 177\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 178\n",
      "Random Action selected : 1\n",
      "Maximum value in this state: 128\n",
      "Iteration: 179\n",
      "<tf.Variable 'Q:0' shape=(16, 4) dtype=float32, numpy=\n",
      "array([[1.4455035 , 1.408     , 0.        , 1.2401404 ],\n",
      "       [0.        , 0.        , 0.        , 2.2757888 ],\n",
      "       [0.        , 0.        , 2.73953   , 0.        ],\n",
      "       [0.15999997, 0.        , 0.        , 0.        ],\n",
      "       [0.608     , 5.760337  , 0.56033283, 3.029499  ],\n",
      "       [7.0435476 , 6.8866153 , 7.376744  , 5.0953555 ],\n",
      "       [6.1801543 , 6.8251295 , 6.5463896 , 6.918653  ],\n",
      "       [5.4527416 , 2.223184  , 3.1443315 , 2.4517977 ],\n",
      "       [0.4088188 , 2.7140555 , 0.        , 0.5379195 ],\n",
      "       [4.121363  , 4.5445247 , 2.3266973 , 4.3385286 ],\n",
      "       [3.3263307 , 6.5135274 , 6.878083  , 7.6976337 ],\n",
      "       [0.        , 0.        , 0.        , 1.9916799 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [3.104422  , 2.3593607 , 3.5653768 , 2.6274712 ],\n",
      "       [1.4615681 , 0.        , 0.6794773 , 0.608     ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)>\n",
      "Predicted Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 180\n",
      "Random Action selected : 2\n",
      "Maximum value in this state: 128\n",
      "Iteration: 181\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 182\n",
      "Random Action selected : 0\n",
      "Maximum value in this state: 128\n",
      "Iteration: 183\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 184\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 185\n",
      "Random Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 186\n",
      "<tf.Variable 'Q:0' shape=(16, 4) dtype=float32, numpy=\n",
      "array([[1.4455035 , 1.408     , 0.        , 1.2401404 ],\n",
      "       [2.4604156 , 0.        , 1.7295994 , 2.3361735 ],\n",
      "       [0.        , 0.        , 2.73953   , 0.        ],\n",
      "       [0.15999997, 0.        , 0.        , 0.        ],\n",
      "       [0.608     , 5.760337  , 0.56033283, 3.029499  ],\n",
      "       [7.0435476 , 6.8866153 , 7.376744  , 2.7486703 ],\n",
      "       [6.1801543 , 6.8251295 , 6.5463896 , 6.918653  ],\n",
      "       [5.4527416 , 2.223184  , 3.1443315 , 2.4517977 ],\n",
      "       [0.4088188 , 2.7140555 , 0.        , 0.5379195 ],\n",
      "       [4.121363  , 4.5445247 , 2.3266973 , 4.3385286 ],\n",
      "       [3.3263307 , 6.5135274 , 6.878083  , 7.6976337 ],\n",
      "       [0.        , 0.        , 0.        , 1.9916799 ],\n",
      "       [0.        , 0.        , 0.        , 0.        ],\n",
      "       [3.104422  , 2.3593607 , 3.5653768 , 2.6274712 ],\n",
      "       [1.4615681 , 0.        , 0.6794773 , 0.608     ],\n",
      "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)>\n",
      "Predicted Action selected : 3\n",
      "Maximum value in this state: 128\n",
      "Iteration: 187\n",
      "Random Action selected : 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-43b757e97935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgame_2048\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mgame_2048\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGame_2048\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-c74cfc666a4f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(env, T, alpha, gamma, epsilon_i, epsilon_f, n_epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0ma_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#         print(\"Action: {}\".format(a_t))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0ms_t_next_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0ms_t_next\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms_t_next_act\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t_next_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#         print(\"{}\\n{}\".format(\"-\"*50,s_t_next))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\debug.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# attach setter functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\game_2048.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_random_tile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneed_random_tile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\debug.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# attach setter functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\game_2048.py\u001b[0m in \u001b[0;36madd_random_tile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                 \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m                 \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mrandrange\u001b[1;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mistart\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"empty range for randrange()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36m_randbelow\u001b[1;34m(self, n, int, maxsize, type, Method, BuiltinMethod)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m          \u001b[1;31m# 0 <= r < 2**k\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;31m# There's an overridden random() method but no new getrandbits() method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import game_2048\n",
    "env =game_2048.Game_2048()\n",
    "train(env, T=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.normalize(env.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
