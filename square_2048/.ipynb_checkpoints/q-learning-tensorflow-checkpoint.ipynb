{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### $Q$-learning as a Regression Problem\n",
    "\n",
    "When we first learned about $Q$-learning, we used the Bellman equation to learn the $Q$ function:\n",
    "$$\n",
    "Q(s_t, a_t) \\gets Q(s_t, a_t) + \\alpha \\left( r_t + (1-d_t)\\gamma \\max_{a_{t+1}} \\left( Q(s_{t+1}, a_{t+1}) \\right) - Q(s_t, a_t) \\right)\n",
    "$$\n",
    "\n",
    "Compare this to gradient descent for a regression problem:\n",
    "$$\n",
    "\\theta \\gets \\theta - \\alpha 2 \\left( \\hat{y} - y \\right) \\nabla_\\theta \\hat{y}\n",
    "$$\n",
    "\n",
    "These methods are essentially analogous: we update parameters about our function in a manner proportional to the difference between our prediction and the 'true' value. The difference for tabular $Q$-learning is that we essentially have a different parameter for each state-action pair. \n",
    "\n",
    "If we define the following loss function:\n",
    "$$\n",
    "L(\\theta) = \\frac{1}{2} \\left( r_t + (1-d_t)\\gamma \\max_{a_{t+1}} \\left( Q(s_{t+1}, a_{t+1}) \\right) - Q(s_t, a_t) \\right)^2\n",
    "$$\n",
    "\n",
    "Then the gradient descent update rule is exactly the same as our q-learning update rule!\n",
    "\n",
    "### FrozenLake with Tensorflow\n",
    "\n",
    "Before diving deep into using techniques like deep neural networks, I want to show you how we might do $Q$-learning in tensorflow using the same `FrozenLake-v0` environment from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_states, num_actions, \n",
    "                 epsilon_i=1.0, \n",
    "                 epsilon_f=0.0, \n",
    "                 n_epsilon=0.1, \n",
    "                 alpha=0.5, \n",
    "                 gamma = 0.95,\n",
    "                 hidden_layers = []\n",
    "                ):\n",
    "        \n",
    "        self.epsilon_i = epsilon_i\n",
    "        self.epsilon_f = epsilon_f\n",
    "        self.epsilon = epsilon_i\n",
    "        self.n_epsilon = n_epsilon\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.Q = tf.Variable(tf.zeros((num_states, num_actions)), name=\"Q\")\n",
    "        self.optimizer = tf.keras.optimizers.SGD(alpha)\n",
    "\n",
    "    def decay_epsilon(self, n):\n",
    "        self.epsilon = max(\n",
    "            self.epsilon_f, \n",
    "            self.epsilon_i - (n/self.n_epsilon)*(self.epsilon_i - self.epsilon_f))\n",
    "    \n",
    "    def act(self, s_t):\n",
    "#         print(\"np.random.rand(): {} < self.epsilon: {}\".format(np.random.rand(),self.epsilon))\n",
    "        action=-1\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action= np.random.randint(self.num_actions)\n",
    "            print(\"Random Action selected : {}\".format(action))\n",
    "        else:\n",
    "#             max_v_current=[i for i,val in enumerate(s_t) if val == s_t.max()][0]\n",
    "            print(self.Q)\n",
    "#             print(\"np.argmax(self.Q[max_v_current]) = {}\".format(np.argmax(self.Q[max_v_current])))\n",
    "#             print(np.argmax(self.Q.numpy(), axis=0))\n",
    "            action= np.argmax(np.argmax(self.Q.numpy(), axis=0))\n",
    "            \n",
    "            #np.argmax(self.Q[max_v_current])\n",
    "            print(\"Predicted Action selected : {}\".format(action))\n",
    "#         print(\"Action = {}\".format(action))\n",
    "#         print(self.Q)\n",
    "        return action\n",
    "    \n",
    "    def update(self, s_t, a_t, r_t, s_t_next, d_t):\n",
    "#         print(\"------------- update -------------\")\n",
    "#         print(\"*\"*50)\n",
    "#         print(s_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(a_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(r_t)\n",
    "#         print(\"*\"*50)\n",
    "#         print(\"-------------s_t_next-------------\")\n",
    "#         print(s_t_next.transpose())\n",
    "#         print(\"*\"*50)\n",
    "#         print(\"-------------d_t     -------------\")\n",
    "#         print(d_t)\n",
    "        \n",
    "#         print(\"*\"*50)\n",
    "#         print(self.Q[[i for i,val in enumerate(s_t_next) if val == s_t_next.max()][0]])\n",
    "        max_v_next=[i for i,val in enumerate(s_t_next) if val == s_t_next.max()][0]\n",
    "        max_v_current=[i for i,val in enumerate(s_t) if val == s_t.max()][0]\n",
    "#         print(\"*\"*50)\n",
    "#         print(np.max(self.Q[max_v_next]))\n",
    "        Q_next = tf.stop_gradient(np.max(self.Q[max_v_next]))\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = 0.5*tf.reduce_mean(r_t + (1-d_t)*self.gamma*Q_next -  self.Q[max_v_current, a_t])**2\n",
    "        grads = tape.gradient(loss, [self.Q])\n",
    "        self.optimizer.apply_gradients(zip(grads, [self.Q]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data, window=100):\n",
    "    sns.lineplot(\n",
    "        data=data.rolling(window=window).mean()[window-1::window]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env,\n",
    "         T=100000, alpha=0.8, gamma=0.95, epsilon_i = 1.0, epsilon_f = 0.0, n_epsilon = 0.1):\n",
    "#    env = gym.make(env_name)\n",
    "#    num_states = env.observation_space.n\n",
    "#    num_actions = env.action_space.n\n",
    "    num_states=len(env.reset())\n",
    "    num_actions=4\n",
    "    agent = Agent(num_states, num_actions, alpha=alpha, gamma=gamma, epsilon_i=epsilon_i, epsilon_f=epsilon_f, n_epsilon = n_epsilon)\n",
    "    \n",
    "#     print(agent.Q)\n",
    "    rewards = []\n",
    "    episode_rewards = 0\n",
    "    \n",
    "    s_t_act = env.reset()\n",
    "    s_t=s_t_act/np.max(s_t_act)\n",
    "    \n",
    "#     print(s_t)\n",
    "    for t in range(T):\n",
    "        print(\"Iteration: {}\".format(t))\n",
    "#         print(agent.Q)\n",
    "        a_t = agent.act(s_t)\n",
    "#         print(\"Action: {}\".format(a_t))\n",
    "        s_t_next_act, r_t, d_t, info = env.step(a_t)\n",
    "        s_t_next=s_t_next_act/np.max(s_t_next_act)\n",
    "#         print(\"{}\\n{}\".format(\"-\"*50,s_t_next))\n",
    "#         print(\"{}\\n{}\".format(\"-\"*50,r_t))\n",
    "#         print(env.game_state)\n",
    "        agent.update(s_t, a_t, r_t, s_t_next, d_t)\n",
    "        agent.decay_epsilon(t/T)\n",
    "        s_t = s_t_next\n",
    "        episode_rewards += r_t\n",
    "#         print(\"Episode Reward: {}\".format(episode_rewards))\n",
    "#         print(\"Game is dead? {}\".format(d_t))\n",
    "        if d_t:\n",
    "            print(\"saving current episode rewards\")\n",
    "            rewards.append(episode_rewards)\n",
    "            episode_rewards = 0\n",
    "            s_t_act = env.reset()\n",
    "            s_t=s_t_act/np.max(s_t_act)\n",
    "            \n",
    "    plot(pd.DataFrame(rewards))\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Game_2048()\n",
      "GAME_MODE - debug\n",
      "For function Game_2048.__init__, time taken 0.0\n",
      "Random Action selected : 2\n",
      "[[2 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 2 0]]\n",
      "Episode Reward: 6\n",
      "Random Action selected : 1\n",
      "[[0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 4]]\n",
      "Episode Reward: 14\n",
      "Random Action selected : 2\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 8]]\n",
      "Episode Reward: 24\n",
      "Random Action selected : 2\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 0 8]]\n",
      "Episode Reward: 34\n",
      "Random Action selected : 3\n",
      "[[0 2 0 8]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Episode Reward: 46\n",
      "Random Action selected : 1\n",
      "[[2 0 2 8]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Episode Reward: 60\n",
      "Random Action selected : 2\n",
      "[[0 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 8]\n",
      " [2 0 2 2]]\n",
      "Episode Reward: 76\n",
      "Random Action selected : 2\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 8]\n",
      " [2 2 2 2]]\n",
      "Episode Reward: 92\n",
      "Random Action selected : 1\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 0 8]\n",
      " [0 0 0 8]]\n",
      "Episode Reward: 110\n",
      "Random Action selected : 1\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 8]\n",
      " [0 0 0 8]]\n",
      "Episode Reward: 128\n",
      "Random Action selected : 1\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 8]\n",
      " [0 0 0 8]]\n",
      "Episode Reward: 146\n",
      "Random Action selected : 2\n",
      "[[ 2  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  2 16]]\n",
      "Episode Reward: 166\n",
      "Random Action selected : 3\n",
      "[[ 2  0  2 16]\n",
      " [ 0  0  2  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 188\n",
      "Random Action selected : 3\n",
      "[[ 2  0  4 16]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 212\n",
      "Random Action selected : 0\n",
      "[[ 2  4 16  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 238\n",
      "Random Action selected : 0\n",
      "[[ 2  4 16  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 264\n",
      "Random Action selected : 1\n",
      "[[ 0  2  4 16]\n",
      " [ 0  2  0  2]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 292\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  0 16]\n",
      " [ 0  4  4  4]]\n",
      "Episode Reward: 322\n",
      "Random Action selected : 3\n",
      "[[ 0  2  4 16]\n",
      " [ 0  4  2  4]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 354\n",
      "Random Action selected : 3\n",
      "[[ 0  2  4 16]\n",
      " [ 0  4  2  4]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 386\n",
      "Random Action selected : 3\n",
      "[[ 0  2  4 16]\n",
      " [ 0  4  2  4]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 418\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  2  4 16]\n",
      " [ 0  4  2  4]]\n",
      "Episode Reward: 452\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  2  0]\n",
      " [ 0  2  4 16]\n",
      " [ 0  4  2  4]]\n",
      "Episode Reward: 486\n",
      "Random Action selected : 1\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  2  4 16]\n",
      " [ 2  4  2  4]]\n",
      "Episode Reward: 522\n",
      "Random Action selected : 0\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  2]\n",
      " [ 2  4 16  0]\n",
      " [ 2  4  2  4]]\n",
      "Episode Reward: 560\n",
      "Random Action selected : 3\n",
      "[[ 4  8 16  2]\n",
      " [ 2  0  2  4]\n",
      " [ 0  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 600\n",
      "Random Action selected : 0\n",
      "[[ 4  8 16  2]\n",
      " [ 8  0  0  0]\n",
      " [ 2  2  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 642\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 8  8  0  0]\n",
      " [ 2  2 16  2]]\n",
      "Episode Reward: 686\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 8  8  0  0]\n",
      " [ 2  2 16  2]]\n",
      "Episode Reward: 730\n",
      "Random Action selected : 0\n",
      "[[ 0  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [16  2  0  0]\n",
      " [ 4 16  2  0]]\n",
      "Episode Reward: 776\n",
      "Random Action selected : 1\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  4  2]\n",
      " [ 0  2 16  2]\n",
      " [ 0  4 16  2]]\n",
      "Episode Reward: 824\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  2  4  2]\n",
      " [ 0  4 32  4]]\n",
      "Episode Reward: 874\n",
      "Random Action selected : 1\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  2  4  2]\n",
      " [ 0  4 32  4]]\n",
      "Episode Reward: 926\n",
      "Random Action selected : 0\n",
      "[[ 2  0  0  0]\n",
      " [ 2  0  0  2]\n",
      " [ 2  4  2  0]\n",
      " [ 4 32  4  0]]\n",
      "Episode Reward: 980\n",
      "Random Action selected : 0\n",
      "[[ 2  0  0  2]\n",
      " [ 4  0  0  0]\n",
      " [ 2  4  2  0]\n",
      " [ 4 32  4  0]]\n",
      "Episode Reward: 1036\n",
      "Random Action selected : 0\n",
      "[[ 4  0  2  0]\n",
      " [ 4  0  0  0]\n",
      " [ 2  4  2  0]\n",
      " [ 4 32  4  0]]\n",
      "Episode Reward: 1094\n",
      "Random Action selected : 1\n",
      "[[ 0  0  4  2]\n",
      " [ 0  0  0  4]\n",
      " [ 2  2  4  2]\n",
      " [ 0  4 32  4]]\n",
      "Episode Reward: 1154\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 2  2  8  2]\n",
      " [ 2  4 32  4]]\n",
      "Episode Reward: 1216\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 2  2  8  2]\n",
      " [ 4  4 32  4]]\n",
      "Episode Reward: 1280\n",
      "Random Action selected : 3\n",
      "[[ 2  2  8  2]\n",
      " [ 4  4 32  4]\n",
      " [ 0  0  0  2]\n",
      " [ 0  2  0  4]]\n",
      "Episode Reward: 1346\n",
      "Random Action selected : 3\n",
      "[[ 2  2  8  2]\n",
      " [ 4  4 32  4]\n",
      " [ 0  2  0  2]\n",
      " [ 0  0  0  4]]\n",
      "Episode Reward: 1412\n",
      "Random Action selected : 1\n",
      "[[ 2  4  8  2]\n",
      " [ 0  8 32  4]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0  0  4]]\n",
      "Episode Reward: 1480\n",
      "Random Action selected : 0\n",
      "[[ 2  4  8  2]\n",
      " [ 8 32  4  0]\n",
      " [ 4  0  0  0]\n",
      " [ 4  2  0  0]]\n",
      "Episode Reward: 1550\n",
      "Random Action selected : 1\n",
      "[[ 2  4  8  2]\n",
      " [ 2  8 32  4]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0  4  2]]\n",
      "Episode Reward: 1622\n",
      "Random Action selected : 0\n",
      "[[ 2  4  8  2]\n",
      " [ 2  8 32  4]\n",
      " [ 4  0  0  0]\n",
      " [ 4  2  0  2]]\n",
      "Episode Reward: 1696\n",
      "Random Action selected : 3\n",
      "[[ 8  4  8  2]\n",
      " [ 4  8 32  4]\n",
      " [ 0  2  0  2]\n",
      " [ 0  0  0  2]]\n",
      "Episode Reward: 1772\n",
      "Random Action selected : 3\n",
      "[[ 8  4  8  2]\n",
      " [ 4  8 32  8]\n",
      " [ 0  2  0  0]\n",
      " [ 0  0  0  2]]\n",
      "Episode Reward: 1850\n",
      "Random Action selected : 3\n",
      "[[ 8  4  8  2]\n",
      " [ 4  8 32  8]\n",
      " [ 0  2  0  2]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 1928\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  4  2  2]\n",
      " [ 8  8  8  8]\n",
      " [ 4  2 32  2]]\n",
      "Episode Reward: 2008\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  4  2  2]\n",
      " [ 8  8  8  8]\n",
      " [ 4  2 32  2]]\n",
      "Episode Reward: 2088\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  4  2  2]\n",
      " [ 8  8  8  8]\n",
      " [ 4  2 32  2]]\n",
      "Episode Reward: 2168\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 0  4  2  2]\n",
      " [ 8  8  8  8]\n",
      " [ 4  2 32  2]]\n",
      "Episode Reward: 2248\n",
      "Random Action selected : 0\n",
      "[[ 0  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [32  0  0  0]\n",
      " [ 4  2 32  2]]\n",
      "Episode Reward: 2330\n",
      "Random Action selected : 3\n",
      "[[ 8  4 32  2]\n",
      " [32  0  0  0]\n",
      " [ 4  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 2414\n",
      "Random Action selected : 0\n",
      "[[ 8  4 32  2]\n",
      " [32  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 0  0  2  0]]\n",
      "Episode Reward: 2500\n",
      "Random Action selected : 3\n",
      "[[ 8  4 32  2]\n",
      " [32  2  2  0]\n",
      " [ 4  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 2588\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  0]\n",
      " [ 8  0  0  0]\n",
      " [32  4 32  0]\n",
      " [ 4  2  4  2]]\n",
      "Episode Reward: 2678\n",
      "Random Action selected : 1\n",
      "[[ 0  2  0  2]\n",
      " [ 0  0  0  8]\n",
      " [ 0 32  4 32]\n",
      " [ 4  2  4  2]]\n",
      "Episode Reward: 2770\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  2]\n",
      " [ 0  2  0  8]\n",
      " [ 0 32  0 32]\n",
      " [ 4  2  8  2]]\n",
      "Episode Reward: 2864\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  8]\n",
      " [ 0 32  2 32]\n",
      " [ 4  2  8  2]]\n",
      "Episode Reward: 2958\n",
      "<tf.Variable 'Q:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[  0.     ,  19.264  ,  27.8528 ,   9.6    ],\n",
      "       [843.9807 , 868.9713 , 972.9006 , 874.1471 ],\n",
      "       [  0.     ,  34.12224,  35.74477,   0.     ],\n",
      "       [  0.     ,   0.     ,   0.     ,   0.     ]], dtype=float32)>\n",
      "Predicted Action selected : 0\n",
      "[[ 2  0  2  0]\n",
      " [ 2  8  0  0]\n",
      " [32  2 32  0]\n",
      " [ 4  2  8  2]]\n",
      "Episode Reward: 3054\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 4  0  2  2]\n",
      " [32  8 32  0]\n",
      " [ 4  4  8  2]]\n",
      "Episode Reward: 3152\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  0]\n",
      " [ 4  0  2  0]\n",
      " [32  8 32  2]\n",
      " [ 4  4  8  4]]\n",
      "Episode Reward: 3252\n",
      "Random Action selected : 3\n",
      "[[ 4  8  2  2]\n",
      " [32  4 32  4]\n",
      " [ 4  0  8  0]\n",
      " [ 2  0  0  0]]\n",
      "Episode Reward: 3354\n",
      "Random Action selected : 1\n",
      "[[ 2  4  8  4]\n",
      " [32  4 32  4]\n",
      " [ 0  0  4  8]\n",
      " [ 0  0  0  2]]\n",
      "Episode Reward: 3458\n",
      "Random Action selected : 1\n",
      "[[ 2  4  8  4]\n",
      " [32  4 32  4]\n",
      " [ 0  0  4  8]\n",
      " [ 0  0  0  2]]\n",
      "Episode Reward: 3562\n",
      "Random Action selected : 0\n",
      "[[ 2  4  8  4]\n",
      " [32  4 32  4]\n",
      " [ 4  8  0  0]\n",
      " [ 2  0  2  0]]\n",
      "Episode Reward: 3668\n",
      "Random Action selected : 1\n",
      "[[ 2  4  8  4]\n",
      " [32  4 32  4]\n",
      " [ 0  0  4  8]\n",
      " [ 0  2  0  4]]\n",
      "Episode Reward: 3776\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  8  0]\n",
      " [ 2  8 32 16]\n",
      " [32  2  4  4]]\n",
      "Episode Reward: 3886\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  8  0]\n",
      " [ 2  8 32 16]\n",
      " [32  2  4  4]]\n",
      "Episode Reward: 3996\n",
      "Random Action selected : 0\n",
      "[[ 2  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 2  8 32 16]\n",
      " [32  2  8  2]]\n",
      "Episode Reward: 4108\n",
      "Random Action selected : 1\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  8]\n",
      " [ 2  8 32 16]\n",
      " [32  2  8  2]]\n",
      "Episode Reward: 4222\n",
      "Random Action selected : 2\n",
      "[[ 0  0  2  2]\n",
      " [ 0  2  0  8]\n",
      " [ 2  8 32 16]\n",
      " [32  2  8  2]]\n",
      "Episode Reward: 4338\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  2  8]\n",
      " [ 2  8 32 16]\n",
      " [32  2  8  2]]\n",
      "Episode Reward: 4454\n",
      "Random Action selected : 3\n",
      "[[ 2  2  2  2]\n",
      " [32  8 32  8]\n",
      " [ 0  2  8 16]\n",
      " [ 0  0  2  2]]\n",
      "Episode Reward: 4572\n",
      "Random Action selected : 0\n",
      "[[ 8  0  0  0]\n",
      " [32  8 32  8]\n",
      " [ 2  8 16  0]\n",
      " [ 4  2  0  0]]\n",
      "Episode Reward: 4692\n",
      "Random Action selected : 3\n",
      "[[ 8 16 32  8]\n",
      " [32  2 16  0]\n",
      " [ 2  0  2  0]\n",
      " [ 4  0  0  0]]\n",
      "Episode Reward: 4814\n",
      "Random Action selected : 2\n",
      "[[ 8  0  0  2]\n",
      " [32  0 32  0]\n",
      " [ 2 16 16  0]\n",
      " [ 4  2  2  8]]\n",
      "Episode Reward: 4938\n",
      "Random Action selected : 2\n",
      "[[ 8  0  0  0]\n",
      " [32  0 32  0]\n",
      " [ 2 16 16  2]\n",
      " [ 4  2  2  8]]\n",
      "Episode Reward: 5062\n",
      "Random Action selected : 3\n",
      "[[ 8 16 32  2]\n",
      " [32  2 16  8]\n",
      " [ 2  0  2  0]\n",
      " [ 4  2  0  0]]\n",
      "Episode Reward: 5188\n",
      "Random Action selected : 3\n",
      "[[ 8 16 32  2]\n",
      " [32  4 16  8]\n",
      " [ 2  0  2  0]\n",
      " [ 4  0  2  0]]\n",
      "Episode Reward: 5316\n",
      "Random Action selected : 1\n",
      "[[ 8 16 32  2]\n",
      " [32  4 16  8]\n",
      " [ 0  0  2  4]\n",
      " [ 0  0  4  2]]\n",
      "Episode Reward: 5446\n",
      "Random Action selected : 3\n",
      "[[ 8 16 32  2]\n",
      " [32  4 16  8]\n",
      " [ 2  0  2  4]\n",
      " [ 0  0  4  2]]\n",
      "Episode Reward: 5578\n",
      "Random Action selected : 2\n",
      "[[ 0  2 32  2]\n",
      " [ 8  0 16  8]\n",
      " [32 16  2  4]\n",
      " [ 2  4  4  2]]\n",
      "Episode Reward: 5712\n",
      "Random Action selected : 3\n",
      "[[ 8  2 32  2]\n",
      " [32 16 16  8]\n",
      " [ 2  4  2  4]\n",
      " [ 0  2  4  2]]\n",
      "Episode Reward: 5848\n",
      "<tf.Variable 'Q:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[   0.     ,   19.264  ,   27.8528 ,    9.6    ],\n",
      "       [1364.2389 , 1530.1122 , 1607.7473 , 1648.0283 ],\n",
      "       [   0.     ,   34.12224,   35.74477,    0.     ],\n",
      "       [   0.     ,    0.     ,    0.     ,    0.     ]], dtype=float32)>\n",
      "Predicted Action selected : 0\n",
      "[[ 8  2 32  2]\n",
      " [64  8  0  2]\n",
      " [ 2  4  2  4]\n",
      " [ 2  4  2  0]]\n",
      "Episode Reward: 5986\n",
      "Random Action selected : 3\n",
      "[[ 8  2 32  8]\n",
      " [64 16  4  0]\n",
      " [ 4  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Episode Reward: 6126\n",
      "Random Action selected : 0\n",
      "[[ 8  2 32  8]\n",
      " [64 16  4  0]\n",
      " [ 4  2  0  0]\n",
      " [ 2  0  0  0]]\n",
      "Episode Reward: 6268\n",
      "Random Action selected : 2\n",
      "[[ 8  0  0  0]\n",
      " [64  2  2  0]\n",
      " [ 4 16 32  0]\n",
      " [ 2  2  4  8]]\n",
      "Episode Reward: 6412\n",
      "Random Action selected : 3\n",
      "[[ 8  2  2  8]\n",
      " [64 16 32  0]\n",
      " [ 4  2  4  2]\n",
      " [ 2  0  0  0]]\n",
      "Episode Reward: 6558\n",
      "Random Action selected : 3\n",
      "[[ 8  2  2  8]\n",
      " [64 16 32  2]\n",
      " [ 4  2  4  0]\n",
      " [ 2  0  0  0]]\n",
      "Episode Reward: 6704\n",
      "Random Action selected : 1\n",
      "[[ 0  8  4  8]\n",
      " [64 16 32  2]\n",
      " [ 0  4  2  4]\n",
      " [ 2  0  0  2]]\n",
      "Episode Reward: 6852\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  8]\n",
      " [ 2  8  4  2]\n",
      " [64 16 32  4]\n",
      " [ 2  4  2  2]]\n",
      "Episode Reward: 7002\n",
      "Random Action selected : 1\n",
      "[[ 0  0  0  8]\n",
      " [ 2  8  4  2]\n",
      " [64 16 32  4]\n",
      " [ 0  2  2  8]]\n",
      "Episode Reward: 7154\n",
      "Random Action selected : 1\n",
      "[[ 0  0  0  8]\n",
      " [ 2  8  4  2]\n",
      " [64 16 32  4]\n",
      " [ 2  0  4  8]]\n",
      "Episode Reward: 7308\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  8]\n",
      " [ 2  2  4  2]\n",
      " [64  8 32  4]\n",
      " [ 2 16  4  8]]\n",
      "Episode Reward: 7464\n",
      "Random Action selected : 2\n",
      "[[ 0  0  0  8]\n",
      " [ 2  2  4  2]\n",
      " [64  8 32  4]\n",
      " [ 2 16  4  8]]\n",
      "Episode Reward: 7620\n",
      "Random Action selected : 3\n",
      "[[ 2  2  4  8]\n",
      " [64  8 32  2]\n",
      " [ 2 16  4  4]\n",
      " [ 0  2  0  8]]\n",
      "Episode Reward: 7778\n",
      "Random Action selected : 0\n",
      "[[16  2  0  0]\n",
      " [64  8 32  2]\n",
      " [ 2 16  8  0]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 7938\n",
      "Random Action selected : 3\n",
      "[[16  2 32  2]\n",
      " [64  8  8  0]\n",
      " [ 4 16  0  0]\n",
      " [ 2  8  0  0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward: 8100\n",
      "Random Action selected : 3\n",
      "[[16  2 32  2]\n",
      " [64  8  8  0]\n",
      " [ 4 16  0  0]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 8262\n",
      "Random Action selected : 2\n",
      "[[16  2  2  0]\n",
      " [64  8  0  0]\n",
      " [ 4 16 32  0]\n",
      " [ 2  8  8  2]]\n",
      "Episode Reward: 8426\n",
      "Random Action selected : 3\n",
      "[[16  2  2  2]\n",
      " [64  8 32  0]\n",
      " [ 4 16  8  0]\n",
      " [ 2  8  0  2]]\n",
      "Episode Reward: 8592\n",
      "Random Action selected : 3\n",
      "[[16  2  2  4]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  0]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 8760\n",
      "Random Action selected : 0\n",
      "[[16  8  0  0]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 8930\n",
      "Random Action selected : 1\n",
      "[[ 2  0 16  8]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 0  0  2  8]]\n",
      "Episode Reward: 9102\n",
      "Random Action selected : 0\n",
      "[[ 2 16  8  2]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 9276\n",
      "Random Action selected : 0\n",
      "[[ 2 16  8  2]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  0  0]]\n",
      "Episode Reward: 9450\n",
      "Random Action selected : 3\n",
      "[[ 2 16  8  4]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  0]\n",
      " [ 2  8  2  0]]\n",
      "Episode Reward: 9626\n",
      "Random Action selected : 0\n",
      "[[ 2 16  8  4]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  2  0]]\n",
      "Episode Reward: 9804\n",
      "Random Action selected : 0\n",
      "[[ 2 16  8  4]\n",
      " [64  8 32  2]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  2  0]]\n",
      "Episode Reward: 9982\n",
      "Random Action selected : 2\n",
      "[[ 2 16  8  2]\n",
      " [64  8 32  0]\n",
      " [ 4 16  8  0]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 10162\n",
      "Random Action selected : 2\n",
      "[[ 2 16  8  0]\n",
      " [64  8 32  0]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 10342\n",
      "Random Action selected : 1\n",
      "[[ 0  2 16  8]\n",
      " [ 2 64  8 32]\n",
      " [ 4 16  8  2]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 10524\n",
      "Random Action selected : 3\n",
      "[[ 2  2 32  8]\n",
      " [ 4 64  2 32]\n",
      " [ 2 16  0  2]\n",
      " [ 0  8  2  8]]\n",
      "Episode Reward: 10708\n",
      "Random Action selected : 0\n",
      "[[ 4 32  8  2]\n",
      " [ 4 64  2 32]\n",
      " [ 2 16  2  0]\n",
      " [ 8  2  8  0]]\n",
      "Episode Reward: 10894\n",
      "Random Action selected : 1\n",
      "[[ 4 32  8  2]\n",
      " [ 4 64  2 32]\n",
      " [ 2  2 16  2]\n",
      " [ 0  8  2  8]]\n",
      "Episode Reward: 11082\n",
      "Random Action selected : 3\n",
      "[[ 8 32  8  2]\n",
      " [ 2 64  2 32]\n",
      " [ 0  2 16  2]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 11272\n",
      "Random Action selected : 1\n",
      "[[ 8 32  8  2]\n",
      " [ 2 64  2 32]\n",
      " [ 2  2 16  2]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 11464\n",
      "Random Action selected : 0\n",
      "[[ 8 32  8  2]\n",
      " [ 2 64  2 32]\n",
      " [ 4 16  2  2]\n",
      " [ 2  8  2  8]]\n",
      "Episode Reward: 11658\n",
      "Random Action selected : 2\n",
      "[[ 8 32  2  2]\n",
      " [ 2 64  8 32]\n",
      " [ 4 16  2  2]\n",
      " [ 2  8  4  8]]\n",
      "Episode Reward: 11854\n",
      "Random Action selected : 1\n",
      "[[ 0  8 32  4]\n",
      " [ 2 64  8 32]\n",
      " [ 2  4 16  4]\n",
      " [ 2  8  4  8]]\n",
      "Episode Reward: 12052\n",
      "Random Action selected : 3\n",
      "[[ 4  8 32  4]\n",
      " [ 2 64  8 32]\n",
      " [ 0  4 16  4]\n",
      " [ 2  8  4  8]]\n",
      "Episode Reward: 12252\n",
      "Random Action selected : 2\n",
      "[[ 0  8 32  4]\n",
      " [ 0 64  8 32]\n",
      " [ 2  4 16  4]\n",
      " [ 8  8  4  8]]\n",
      "Episode Reward: 12454\n",
      "Random Action selected : 2\n",
      "[[ 0  8 32  4]\n",
      " [ 0 64  8 32]\n",
      " [ 2  4 16  4]\n",
      " [ 8  8  4  8]]\n",
      "Episode Reward: 12656\n",
      "Random Action selected : 2\n",
      "[[ 0  8 32  4]\n",
      " [ 0 64  8 32]\n",
      " [ 2  4 16  4]\n",
      " [ 8  8  4  8]]\n",
      "Episode Reward: 12858\n",
      "Random Action selected : 0\n",
      "[[ 8 32  4  0]\n",
      " [64  8 32  0]\n",
      " [ 2  4 16  4]\n",
      " [16  4  8  2]]\n",
      "Episode Reward: 13062\n",
      "Random Action selected : 0\n",
      "[[ 8 32  4  0]\n",
      " [64  8 32  0]\n",
      " [ 2  4 16  4]\n",
      " [16  4  8  2]]\n",
      "Episode Reward: 13266\n",
      "Random Action selected : 1\n",
      "[[ 2  8 32  4]\n",
      " [ 0 64  8 32]\n",
      " [ 2  4 16  4]\n",
      " [16  4  8  2]]\n",
      "Episode Reward: 13472\n",
      "Random Action selected : 0\n",
      "[[ 2  8 32  4]\n",
      " [64  8 32  2]\n",
      " [ 2  4 16  4]\n",
      " [16  4  8  2]]\n",
      "Episode Reward: 13680\n",
      "Random Action selected : 0\n",
      "[[ 2  8 32  4]\n",
      " [64  8 32  2]\n",
      " [ 2  4 16  4]\n",
      " [16  4  8  2]]\n",
      "Episode Reward: 13888\n",
      "Random Action selected : 2\n",
      "[[ 2  0  0  4]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [16 16  8  2]]\n",
      "Episode Reward: 14098\n",
      "Random Action selected : 2\n",
      "[[ 2  0  0  4]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [16 16  8  2]]\n",
      "Episode Reward: 14308\n",
      "Random Action selected : 2\n",
      "[[ 2  0  0  4]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [16 16  8  2]]\n",
      "Episode Reward: 14518\n",
      "Random Action selected : 0\n",
      "[[ 2  4  0  0]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [32  8  2  2]]\n",
      "Episode Reward: 14730\n",
      "Random Action selected : 0\n",
      "[[ 2  4  0  2]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [32  8  4  0]]\n",
      "Episode Reward: 14944\n",
      "Random Action selected : 1\n",
      "[[ 2  2  4  2]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [ 0 32  8  4]]\n",
      "Episode Reward: 15160\n",
      "Random Action selected : 0\n",
      "[[ 8  2  0  0]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [32  8  4  2]]\n",
      "Episode Reward: 15378\n",
      "Random Action selected : 1\n",
      "[[ 2  0  8  2]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [32  8  4  2]]\n",
      "Episode Reward: 15598\n",
      "Random Action selected : 1\n",
      "[[ 0  2  8  2]\n",
      " [64  2 64  2]\n",
      " [ 2  8 16  4]\n",
      " [32  8  4  2]]\n",
      "Episode Reward: 15818\n",
      "Random Action selected : 3\n",
      "[[64  4  8  8]\n",
      " [ 2 16 64  2]\n",
      " [32  2 16  0]\n",
      " [ 0  0  4  0]]\n",
      "Episode Reward: 16040\n",
      "Random Action selected : 0\n",
      "[[64  4 16  0]\n",
      " [ 2 16 64  2]\n",
      " [32  2 16  0]\n",
      " [ 4  0  0  2]]\n",
      "Episode Reward: 16264\n",
      "Random Action selected : 2\n",
      "[[64  0  0  0]\n",
      " [ 2  4 16  0]\n",
      " [32 16 64  2]\n",
      " [ 4  2 16  4]]\n",
      "Episode Reward: 16490\n",
      "Random Action selected : 3\n",
      "[[64  4 16  2]\n",
      " [ 2 16 64  4]\n",
      " [32  2 16  0]\n",
      " [ 4  0  0  2]]\n",
      "Episode Reward: 16718\n",
      "Random Action selected : 2\n",
      "[[64  0  2  0]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 16948\n",
      "Random Action selected : 0\n",
      "[[64  2  2  0]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 17180\n",
      "Random Action selected : 2\n",
      "[[64  2  2  2]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 17414\n",
      "Random Action selected : 0\n",
      "[[64  4  2  2]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 17650\n",
      "Random Action selected : 1\n",
      "[[ 2  0 64  8]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 17888\n",
      "Random Action selected : 0\n",
      "[[ 2 64  8  2]\n",
      " [ 2  4 16  2]\n",
      " [32 16 64  4]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 18128\n",
      "Random Action selected : 2\n",
      "[[ 0 64  8  0]\n",
      " [ 4  4 16  2]\n",
      " [32 16 64  8]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 18370\n",
      "Random Action selected : 2\n",
      "[[ 0 64  8  0]\n",
      " [ 4  4 16  2]\n",
      " [32 16 64  8]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 18612\n",
      "Random Action selected : 0\n",
      "[[64  8  0  0]\n",
      " [ 8 16  2  2]\n",
      " [32 16 64  8]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 18856\n",
      "Random Action selected : 2\n",
      "[[64  0  0  2]\n",
      " [ 8  8  2  2]\n",
      " [32 32 64  8]\n",
      " [ 4  2 16  2]]\n",
      "Episode Reward: 19102\n",
      "Random Action selected : 1\n",
      "[[  2   0  64   2]\n",
      " [  0   0  16   4]\n",
      " [  0   0 128   8]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 19350\n",
      "Random Action selected : 3\n",
      "[[  2   2  64   2]\n",
      " [  4   0  16   4]\n",
      " [  0   0 128   8]\n",
      " [  2   0  16   2]]\n",
      "Episode Reward: 19600\n",
      "Random Action selected : 2\n",
      "[[  0   0  64   2]\n",
      " [  2   0  16   4]\n",
      " [  4   2 128   8]\n",
      " [  2   2  16   2]]\n",
      "Episode Reward: 19852\n",
      "Random Action selected : 1\n",
      "[[  0   0  64   2]\n",
      " [  0   2  16   4]\n",
      " [  4   2 128   8]\n",
      " [  2   4  16   2]]\n",
      "Episode Reward: 20106\n",
      "Random Action selected : 2\n",
      "[[  0   2  64   2]\n",
      " [  0   0  16   4]\n",
      " [  4   0 128   8]\n",
      " [  2   8  16   2]]\n",
      "Episode Reward: 20362\n",
      "Random Action selected : 2\n",
      "[[  0   0  64   2]\n",
      " [  0   0  16   4]\n",
      " [  4   2 128   8]\n",
      " [  2   8  16   2]]\n",
      "Episode Reward: 20618\n",
      "Random Action selected : 1\n",
      "[[  0   0  64   2]\n",
      " [  0   2  16   4]\n",
      " [  4   2 128   8]\n",
      " [  2   8  16   2]]\n",
      "Episode Reward: 20876\n",
      "Random Action selected : 1\n",
      "[[  0   0  64   2]\n",
      " [  0   2  16   4]\n",
      " [  4   2 128   8]\n",
      " [  2   8  16   2]]\n",
      "Episode Reward: 21134\n",
      "Random Action selected : 3\n",
      "[[  4   4  64   2]\n",
      " [  2   8  16   4]\n",
      " [  2   0 128   8]\n",
      " [  0   0  16   2]]\n",
      "Episode Reward: 21394\n",
      "Random Action selected : 0\n",
      "[[  8  64   2   0]\n",
      " [  2   8  16   4]\n",
      " [  2 128   8   0]\n",
      " [ 16   2   2   0]]\n",
      "Episode Reward: 21656\n",
      "Random Action selected : 2\n",
      "[[  0  64   2   2]\n",
      " [  8   8  16   0]\n",
      " [  4 128   8   0]\n",
      " [ 16   2   2   4]]\n",
      "Episode Reward: 21920\n",
      "Random Action selected : 2\n",
      "[[  0  64   2   0]\n",
      " [  8   8  16   0]\n",
      " [  4 128   8   2]\n",
      " [ 16   2   2   4]]\n",
      "Episode Reward: 22184\n",
      "Random Action selected : 2\n",
      "[[  0  64   2   0]\n",
      " [  8   8  16   0]\n",
      " [  4 128   8   2]\n",
      " [ 16   2   2   4]]\n",
      "Episode Reward: 22448\n",
      "Random Action selected : 0\n",
      "[[ 64   2   2   0]\n",
      " [ 32   0   0   0]\n",
      " [  4 128   8   2]\n",
      " [ 16   8   0   0]]\n",
      "Episode Reward: 22714\n",
      "Random Action selected : 3\n",
      "[[ 64   2   2   2]\n",
      " [ 32 128   8   0]\n",
      " [  4   8   0   0]\n",
      " [ 16   2   0   0]]\n",
      "Episode Reward: 22982\n",
      "Random Action selected : 0\n",
      "[[ 64   4   2   0]\n",
      " [ 32 128   8   0]\n",
      " [  4   8   0   2]\n",
      " [ 16   2   0   0]]\n",
      "Episode Reward: 23252\n",
      "Random Action selected : 2\n",
      "[[ 64   4   2   0]\n",
      " [ 32 128   0   0]\n",
      " [  4   8   2   0]\n",
      " [ 16   2   8   2]]\n",
      "Episode Reward: 23524\n",
      "Random Action selected : 1\n",
      "[[  0  64   4   2]\n",
      " [  0   0  32 128]\n",
      " [  2   4   8   2]\n",
      " [ 16   2   8   2]]\n",
      "Episode Reward: 23798\n",
      "Random Action selected : 1\n",
      "[[  0  64   4   2]\n",
      " [  0   0  32 128]\n",
      " [  2   4   8   2]\n",
      " [ 16   2   8   2]]\n",
      "Episode Reward: 24072\n",
      "Random Action selected : 3\n",
      "[[  2  64   4   2]\n",
      " [ 16   4  32 128]\n",
      " [  0   2  16   4]\n",
      " [  0   2   0   0]]\n",
      "Episode Reward: 24348\n",
      "Random Action selected : 1\n",
      "[[  2  64   4   2]\n",
      " [ 16   4  32 128]\n",
      " [  0   2  16   4]\n",
      " [  2   0   0   2]]\n",
      "Episode Reward: 24626\n",
      "Random Action selected : 2\n",
      "[[  2   0   0   2]\n",
      " [  2  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  2   2  16   2]]\n",
      "Episode Reward: 24906\n",
      "Random Action selected : 3\n",
      "[[  4  64   4   2]\n",
      " [ 16   4  32 128]\n",
      " [  2   2  16   4]\n",
      " [  2   0   0   2]]\n",
      "Episode Reward: 25188\n",
      "Random Action selected : 2\n",
      "[[  0   0   2   2]\n",
      " [  4  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 25472\n",
      "Random Action selected : 2\n",
      "[[  0   0   2   2]\n",
      " [  4  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 25756\n",
      "Random Action selected : 1\n",
      "[[  2   0   0   4]\n",
      " [  4  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 26042\n",
      "Random Action selected : 1\n",
      "[[  0   0   2   4]\n",
      " [  4  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 26328\n",
      "Random Action selected : 0\n",
      "[[  2   4   2   0]\n",
      " [  4  64   4 128]\n",
      " [ 16   4  32   4]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 26616\n",
      "Random Action selected : 3\n",
      "[[  2   4   2 128]\n",
      " [  4  64   4   4]\n",
      " [ 16   4  32   2]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 26906\n",
      "Random Action selected : 0\n",
      "[[  2   4   2 128]\n",
      " [  4  64   8   2]\n",
      " [ 16   4  32   2]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 27198\n",
      "Random Action selected : 0\n",
      "[[  2   4   2 128]\n",
      " [  4  64   8   2]\n",
      " [ 16   4  32   2]\n",
      " [  4   2  16   2]]\n",
      "Episode Reward: 27490\n",
      "Random Action selected : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-43b757e97935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgame_2048\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mgame_2048\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGame_2048\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-4e40e0a608ba>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(env, T, alpha, gamma, epsilon_i, epsilon_f, n_epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0ma_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#         print(\"Action: {}\".format(a_t))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0ms_t_next_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0ms_t_next\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms_t_next_act\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_t_next_act\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#         print(\"{}\\n{}\".format(\"-\"*50,s_t_next))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\debug.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# attach setter functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\game_2048.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_random_tile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneed_random_tile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\debug.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# attach setter functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\javascript\\busywithcoding\\square_2048\\game_2048.py\u001b[0m in \u001b[0;36madd_random_tile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m                 \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                     \u001b[0miterator\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mrandrange\u001b[1;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mistart\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"empty range for randrange()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36m_randbelow\u001b[1;34m(self, n, int, maxsize, type, Method, BuiltinMethod)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m          \u001b[1;31m# 0 <= r < 2**k\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;31m# There's an overridden random() method but no new getrandbits() method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import game_2048\n",
    "env =game_2048.Game_2048()\n",
    "train(env, T=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.normalize(env.reset())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
